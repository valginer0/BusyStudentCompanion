# Production GPU Dockerfile - requires NVIDIA GPU
FROM nvidia/cuda:12.2.0-runtime-ubuntu22.04

# Install Python and dependencies
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    git \
    libglib2.0-0 \
    libsm6 \
    libxrender1 \
    libxext6 \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV PYTHONPATH=/app
ENV TRANSFORMERS_CACHE=/cache/huggingface

# Copy requirements.txt before installing dependencies
COPY requirements.txt requirements.txt

# Install GPU version of torch and dependencies FIRST
RUN pip3 install --no-cache-dir torch==2.1.2+cu118 torchvision==0.16.2+cu118 torchaudio==2.1.2+cu118 -f https://download.pytorch.org/whl/torch_stable.html \
    && pip3 install --no-cache-dir -r requirements.txt

# Create a script to check for GPU availability
COPY <<EOF /app/check_gpu.py
import torch
import sys

def check_gpu():
    print("Checking GPU availability...")
    if not torch.cuda.is_available():
        print("ERROR: CUDA is not available! This container requires NVIDIA GPU support.")
        print("Please ensure:")
        print("1. You have an NVIDIA GPU installed")
        print("2. You have installed the NVIDIA drivers")
        print("3. You have the nvidia-container-toolkit installed")
        print("4. You used '--gpus all' when running this container")
        print("\nFalling back to CPU mode, but performance will be significantly degraded.")
        return False
    else:
        gpu_name = torch.cuda.get_device_name(0)
        gpu_count = torch.cuda.device_count()
        print(f"✓ GPU is available! Found {gpu_count} device(s)")
        print(f"✓ Using: {gpu_name}")
        return True

if __name__ == "__main__":
    success = check_gpu()
    if not success and "--require-gpu" in sys.argv:
        sys.exit(1)
EOF

# Copy the rest of the project
COPY . .

# Replace host config with Docker-specific defaults (GPU image)
COPY src/book_to_essay/config.docker.py /app/src/book_to_essay/config.py

# Create startup wrapper script
COPY <<EOF /app/start.sh
#!/bin/bash
python3 /app/check_gpu.py || echo "WARNING: Continuing without GPU acceleration. Performance will be degraded."
exec streamlit run src/book_to_essay/streamlit_app.py
EOF

RUN chmod +x /app/start.sh

# Expose Streamlit port
EXPOSE 8501

CMD ["/app/start.sh"]
