"""Prompt templates for Mistral models."""
from typing import List, Dict, Optional
from src.book_to_essay.prompts.base import PromptTemplate
from src.book_to_essay.prompts.config import PromptConfig


class MistralPromptTemplate(PromptTemplate):
    """Prompt templates for Mistral language models."""
    
    def format_chunk_analysis_prompt(self, config: PromptConfig) -> str:
        """Format a prompt for analyzing a chunk of text for Mistral model.
        
        Args:
            config: PromptConfig object with fields: analysis_text, topic, source_info
            
        Returns:
            A formatted prompt string
        """
        prompt = f"""<s>[INST] You are a literary scholar analyzing literature. Your task is to extract and analyze material from this text excerpt that relates to '{config.topic}'. \n\nTEXT TO ANALYZE:\n{config.analysis_text}\n\nYOUR TASK:\n- Identify key quotes that illustrate '{config.topic}'\n- Note significant themes, motifs, and literary devices related to '{config.topic}'\n- Analyze character development and dialogue that relates to '{config.topic}'\n- Extract evidence for literary analysis about '{config.topic}'\n\nIMPORTANT: Your response must ONLY contain analysis content. DO NOT:\n- Repeat these instructions\n- Include phrases like \"here is my analysis\" or \"as requested\"\n- Include section headers like \"Analysis:\" or \"Key Quotes:\"\n- Refer to yourself, the reader, or the task itself\n- Mention social media, data analysis, AI, or homework\n\nStart directly with substantive analysis. [/INST]"""

        return prompt
    
    def format_essay_generation_prompt(self, config: PromptConfig) -> str:
        """Format a prompt for generating an essay with Mistral model.
        
        Args:
            config: PromptConfig object with fields: analysis_text, topic, style, word_limit, source_info
            
        Returns:
            A formatted prompt string
        """
        prompt = f"""<s>[INST] You are writing an essay as a literary scholar. Please use the following specifications:\n\nTopic to analyze: {config.topic}\nPreferred style: {config.style}\nWord limit: {config.word_limit}\nSpecific analysis text (if any): {config.analysis_text if config.analysis_text else 'N/A'}\n\nWrite a well-structured, {config.style} essay analyzing '{config.topic}' based on the provided literary analysis.\n\nCONTENT TO USE:\n{config.analysis_text}\n\n**DO NOT INCLUDE ANY INSTRUCTIONS IN YOUR RESPONSE.**\n**START DIRECTLY WITH THE ESSAY - BEGIN WITH THE FIRST PARAGRAPH OF YOUR ESSAY.**\n**DO NOT INCLUDE NUMBERED POINTS, ESSAY SPECIFICATIONS, OR META COMMENTARY.**"""

        return prompt
    
    def format_fallback_prompt(self, config: PromptConfig) -> str:
        """
        Format a fallback prompt for simpler essay generation with Mistral model.

        NOTE: This method is retained for reference and for error text mapping only.
        It should NOT be used to generate fallback essays. All essay generation failures should raise explicit errors instead of producing fallback content.
        """
        prompt = f"""<s>[INST] Write a {config.word_limit}-word {config.style} essay analyzing '{config.topic}' in literature. Use MLA format and include textual evidence. Begin directly with your essay text. [/INST]"""
        
        return prompt
    
    def extract_response(self, generated_text: str) -> str:
        """Extract the model's response from the generated text.
        
        Args:
            generated_text: The raw text generated by the model
            
        Returns:
            The extracted response
        """
        # Extract only the essay part (after the prompt)
        if "[/INST]" in generated_text:
            return generated_text.split("[/INST]")[1].strip()
        return generated_text
